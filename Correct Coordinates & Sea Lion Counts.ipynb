{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct Coordinates & Sea Lion Counts \n",
    "*by LivingProgram*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Explanation\n",
    "## Introduction\n",
    "In this competition we were given dotted training files as labels for the sea lions in each image instead of coordinates. Not only are the dotted training files useless without coordinates, but many of the reported numbers in *train.csv* are incorrect. \n",
    "\n",
    "**The goal of this kernel is to illustrate exactly what I did to generate a coordinates file, and a corrected *train.csv*.**\n",
    "\n",
    "These steps do not need to be performed again, you can just download the coordinates file [here](https://github.com/LivingProgram/kaggle-sea-lion-data/blob/master/correct_coordinates.csv) and count file [here](https://github.com/LivingProgram/kaggle-sea-lion-data/blob/master/correct_train.csv), then check my results using the coordinate marking function in the \"Visualizing Coordinates\" section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I will cover:\n",
    "- **Setting Up Folder Structure**\n",
    "- **Creation of Initial Coordinates File**, using [Radu's Method](https://www.kaggle.com/radustoicescu/noaa-fisheries-steller-sea-lion-population-count/get-coordinates-using-blob-detection)\n",
    "- **Visualizing Coordinates**, using [Radu's Method](https://www.kaggle.com/radustoicescu/noaa-fisheries-steller-sea-lion-population-count/get-coordinates-using-blob-detection)\n",
    "- **Correcting Initial Coordinates File**\n",
    "- **Correcting *train.csv***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Folder Structure\n",
    "*you can setup your folders however you want, but to be compatible with the code below, I will illustrate my folder structure**\n",
    "\n",
    "I have 3 folders:\n",
    "1. the \"code\" folder contains this kernel\n",
    "2. the \"data\" folder contains the extracted \"Test\", \"Train\" and \"TrainDotted\" data folders \n",
    "3. the \"output\" folder is where the \"correct_coordinates.csv\" and \"correct_train.csv\" file will be created\n",
    "\n",
    "<img style=\"float: left;border:5px solid black;\" src=\"folder_structure.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Initial Coordinates File\n",
    "*[Radu's Method](https://www.kaggle.com/radustoicescu/noaa-fisheries-steller-sea-lion-population-count/get-coordinates-using-blob-detection) was implemented here to extract the coordinates*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "from tqdm import tqdm # nice progress bars\n",
    "%matplotlib inline\n",
    "\n",
    "# constants\n",
    "TRAIN_PATH = '../data/Train/'\n",
    "DOTTED_PATH = '../data/TrainDotted/'\n",
    "OUT_PATH = '../output/'\n",
    "\n",
    "ALL_FILE_NAMES = os.listdir(DOTTED_PATH) # all our training file names\n",
    "ALL_FILE_NAMES = sorted(ALL_FILE_NAMES, key = lambda item: int(item.partition('.')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact some images are mismatched in the training set, and will not work for this method (reference to [datacanary's post](https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count/discussion/30895)), I removed those images from the entire list of training files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MISMATCHED_TRAIN = [3, 7, 9, 21, 30, 34, 71, 81, 89, 97, 151, 184, 215, 234, 242, 268, 290, 311, 331, 344, 380, 384, 406, 421, 469, 475, 490, 499, 507, 530, 531, 605, 607, 614, 621, 638, 644, 687, 712, 721, 767, 779, 781, 794, 800, 811, 839, 840, 869, 882, 901, 903, 905, 909, 913, 927, 946]\n",
    "\n",
    "FILE_NAMES = []\n",
    "for filename in ALL_FILE_NAMES:\n",
    "    if int(filename.partition('.')[0]) in MISMATCHED_TRAIN:\n",
    "        pass\n",
    "    else:\n",
    "        FILE_NAMES.append(filename) # create FILE_NAMES without MISMATCHED_TRAIN images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I created two pandas dataframes that will later be saved to csv files. One of them (**count_df**), will record the number of each category of sea lion the method was able to discover in the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(index = FILE_NAMES, columns = [\"adult_males\", \"subadult_males\", \"adult_females\", \"juveniles\", \"pups\"]).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other dataframe (**coordinates_df**), will record the coordinates of every discovered sea lion (**y_coord**, **x_coord**), the image the sea lion is from (**filename**), and the category of the sea lion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coordinates_df = pd.DataFrame(columns = [\"filename\", \"y_coord\", \"x_coord\", \"category\"]).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I iterated over all the training files, and extracted the **y_coord**, **x_coord**, and **category** according to [Radu's Method](https://www.kaggle.com/radustoicescu/noaa-fisheries-steller-sea-lion-population-count/get-coordinates-using-blob-detection), and saved the count_df dataframe to **initial_count.csv**, and the coordinates_df dataframe to **initial_coordinates.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for filename in tqdm(FILE_NAMES):\n",
    "    img_dotted = cv2.imread(DOTTED_PATH + filename)\n",
    "    img_train = cv2.imread(TRAIN_PATH + filename)\n",
    "    img_diff = cv2.absdiff(img_train , img_dotted) \n",
    "\n",
    "    mask_1 = cv2.cvtColor(img_dotted, cv2.COLOR_BGR2GRAY)\n",
    "    mask_1[mask_1 < 20] = 0\n",
    "    mask_1[mask_1 > 0] = 255\n",
    "\n",
    "    mask_2 = cv2.cvtColor(img_train, cv2.COLOR_BGR2GRAY)\n",
    "    mask_2[mask_2 < 20] = 0\n",
    "    mask_2[mask_2 > 0] = 255\n",
    "\n",
    "    img_diff = cv2.bitwise_or(img_diff, img_diff, mask=mask_1)\n",
    "    img_diff = cv2.bitwise_or(img_diff, img_diff, mask=mask_2)\n",
    "\n",
    "    img_diff = cv2.cvtColor(img_diff, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blobs = skimage.feature.blob_log(img_diff, min_sigma=3, max_sigma=4, num_sigma=1, threshold=0.02)\n",
    "\n",
    "    for blob in blobs:\n",
    "        y, x, s = blob\n",
    "        b,g,r = img_dotted[int(y)][int(x)][:]\n",
    "\n",
    "        if r > 204 and g < 29 and b < 26: # RED \n",
    "            count_df[\"adult_males\"][filename] += 1\n",
    "            new_row = pd.Series([filename, int(y), int(x), \"adult_males\"], index=[\"filename\", \"y_coord\", \"x_coord\", \"category\"])\n",
    "            coordinates_df = coordinates_df.append(new_row, ignore_index=True)\n",
    "        elif r > 220 and g < 25 and b > 204: # MAGENTA\n",
    "            count_df[\"subadult_males\"][filename] += 1\n",
    "            new_row = pd.Series([filename, int(y), int(x), \"subadult_males\"], index=[\"filename\", \"y_coord\", \"x_coord\", \"category\"])\n",
    "            coordinates_df = coordinates_df.append(new_row, ignore_index=True)\n",
    "        elif 6 < r < 64 and 156 < g < 199 and b < 52: # GREEN\n",
    "            count_df[\"pups\"][filename] += 1\n",
    "            new_row = pd.Series([filename, int(y), int(x), \"pups\"], index=[\"filename\", \"y_coord\", \"x_coord\", \"category\"])\n",
    "            coordinates_df = coordinates_df.append(new_row, ignore_index=True)\n",
    "        elif r < 78 and  31 < g < 85 and 124 < b < 221: # BLUE\n",
    "            count_df[\"juveniles\"][filename] += 1\n",
    "            new_row = pd.Series([filename, int(y), int(x), \"juveniles\"], index=[\"filename\", \"y_coord\", \"x_coord\", \"category\"])\n",
    "            coordinates_df = coordinates_df.append(new_row, ignore_index=True)\n",
    "        elif 59 < r < 115 and 19 < g < 80 and b < 49:  # BROWN\n",
    "            count_df[\"adult_females\"][filename] += 1\n",
    "            new_row = pd.Series([filename, int(y), int(x), \"adult_females\"], index=[\"filename\", \"y_coord\", \"x_coord\", \"category\"])\n",
    "            coordinates_df = coordinates_df.append(new_row, ignore_index=True)\n",
    "\n",
    "count_df.to_csv(OUT_PATH + 'initial_count.csv')\n",
    "coordinates_df.to_csv(OUT_PATH + 'initial_coordinates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating an Error Report\n",
    "Here I compared the number of sea lions counted by [Radu's method](https://www.kaggle.com/radustoicescu/noaa-fisheries-steller-sea-lion-population-count/get-coordinates-using-blob-detection), to the \"true\" counts given in **train.csv**. The function below takes in the count file (**initial_count.csv**) and compares it to **train.csv**. It then prints a list of images along with the specific categories of sea lions and the predicted values by [Radu's method](https://www.kaggle.com/radustoicescu/noaa-fisheries-steller-sea-lion-population-count/get-coordinates-using-blob-detection), versus the \"true\" values from **train.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report_error(count_file):\n",
    "    # checking that the generated \"initial_count.csv\" matches \"train.csv\" true sea lion numbers\n",
    "    count_df = pd.read_csv(OUT_PATH + count_file, index_col=0)\n",
    "    true_count_df = pd.read_csv(TRAIN_PATH + 'train.csv')\n",
    "    categories = [\"adult_males\", \"subadult_males\", \"adult_females\", \"juveniles\", \"pups\"]\n",
    "\n",
    "    wrong_files_dict = {}\n",
    "    for filename, row in count_df.iterrows():\n",
    "        train_id = int(filename.partition('.')[0])\n",
    "        \n",
    "        wrong_list = []\n",
    "        for category in categories:\n",
    "            predicted_val = int(row[category])\n",
    "            true_val = int(true_count_df[category][train_id])\n",
    "            if predicted_val != true_val:\n",
    "                wrong_list.append([category, predicted_val, true_val])\n",
    "        if len(wrong_list) != 0:\n",
    "            wrong_files_dict[int(filename.partition('.')[0])] = wrong_list\n",
    "    \n",
    "    wrong_files_list = list(wrong_files_dict.keys())\n",
    "    wrong_files_list = sorted(wrong_files_list, key=int)\n",
    "    \n",
    "    for img_id in wrong_files_list:\n",
    "        filename = str(img_id) + '.jpg'\n",
    "        wrong_categories = wrong_files_dict[img_id]\n",
    "        print(filename)\n",
    "        for item in wrong_categories:\n",
    "            category = item[0]\n",
    "            predicted_val = item[1]\n",
    "            true_val = item[2]\n",
    "            print('      ' + category + ': predicted=' + str(predicted_val) + ', True=' + str(true_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report_error('initial_count.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed that there were many images with discrepancies between our generated counts and the **train.csv** counts. The only way to verify whether or not the generated counts were correct or the **train.csv** were correct, was to manually check the coordinates for the images with discrepencies. \n",
    "\n",
    "*Note: Images without discrepancies between generated and **train.csv** counts will not be manually checked, and will be assumed to have accurate coordinates and counts. Other images may be manually checked later, check the bottom for \"Edits\" to the data files*\n",
    "\n",
    "In order to check the validity of the coordinates, they must be visualized on the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Coordinates\n",
    "*[Radu's Method](https://www.kaggle.com/radustoicescu/noaa-fisheries-steller-sea-lion-population-count/get-coordinates-using-blob-detection) was implemented here to visualize the extracted coordinates on the dotted training images*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function defined below (**graph_coord_circles**), all we need to do is give it a list of file names, and the name of the coordinates file generated before (**initial_coordinates.csv**) and the function will draw circles around the coordinates of every file, and save a new jpg file to the output folder with those circles on the image. This will allow us to check if the coordinates are centered correctly on the sea lions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_coord_circles(FILE_NAMES, coord_file):\n",
    "    coordinates_df = pd.read_csv(OUT_PATH + coord_file)\n",
    "\n",
    "    for filename in FILE_NAMES:\n",
    "        new_df = coordinates_df.loc[coordinates_df['filename'] == filename]\n",
    "        dotted_img = cv2.imread(DOTTED_PATH + filename)\n",
    "\n",
    "        for index, row in new_df.iterrows():\n",
    "            if row['category'] == 'adult_males':\n",
    "                cv2.circle(dotted_img, (int(row['x_coord']), int(row['y_coord'])), 8, (0,0,255), 2)\n",
    "            elif row['category'] == 'subadult_males':\n",
    "                cv2.circle(dotted_img, (int(row['x_coord']), int(row['y_coord'])), 8, (250,10,250), 2)\n",
    "            elif row['category'] == 'pups':\n",
    "                cv2.circle(dotted_img, (int(row['x_coord']), int(row['y_coord'])), 8, (20,180,35), 2)\n",
    "            elif row['category'] == 'juveniles':\n",
    "                cv2.circle(dotted_img, (int(row['x_coord']), int(row['y_coord'])), 8, (180,60,30), 2)\n",
    "            elif row['category'] == 'adult_females':\n",
    "                cv2.circle(dotted_img, (int(row['x_coord']), int(row['y_coord'])), 8, (0,42,84), 2)\n",
    "\n",
    "        cv2.imwrite(OUT_PATH + str(filename.partition('.')[0]) + '_marked.jpg', dotted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment the line below and run this cell to generate marked images for all the training files\n",
    "# graph_coord_circles(FILE_NAMES, 'initial_coordinates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually Checking Images\n",
    "Using the images with circles on the coordinates, I checked the images with discrepencies for a couple things:\n",
    "1. Each **circle is centered on a sea lion**, not off in the sea (ensuring that the coordinates are on target)\n",
    "2. Each **sea lion has a circle** on them (ensuring that every sea lion has coordinates that point towards it, and no sea lion is unmarked)\n",
    "3. The **color of the circle**, which indicates category of sea lion, **matches the appearance** of the sea lion (ensures that the sea lions are labeled with not just the correct coordinates but the correct category)\n",
    "\n",
    "Based on the conditions above, the data (coordinates and counts) for a specific image may be incorrect. The correct data is assumed to be the **initial_coordinates.csv**, and I modify the coordinates in **initial_coordinates.csv** by adding coordinates for missing sea lions and removing coordinates for non-sea lions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first load in the data from initial_coordinates.csv\n",
    "correct_coordinates_df = pd.read_csv(OUT_PATH + 'initial_coordinates.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My changes to the images were recorded in the **changes.csv** file located in this repository. In **changes.csv** I made lists of coordinates to add (coord_add column of csv) and coordinates to remove (coord_remove column of csv) for every single image. To apply the changes from the **changes.csv**, coordinates must be added and removed from **initial_coordinates.csv**, and the counts of sea lions in each image readjusted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getting list of good image ids\n",
    "IMG_IDS = [] \n",
    "for filename in FILE_NAMES:\n",
    "    IMG_IDS.append(int(filename.partition('.')[0]))\n",
    "    \n",
    "# function to apply changes, and get corect coordinates and counts\n",
    "def apply_all_changes():\n",
    "    changes_df = pd.read_csv('./changes.csv', index_col='img_id')\n",
    "    \n",
    "    # getting all image ids\n",
    "    img_ids = list(changes_df.index)\n",
    "    \n",
    "    for img_id in img_ids:\n",
    "        # first change new_coord_df\n",
    "        filename = str(img_id) + '.jpg'\n",
    "        mini_changes_df = changes_df.ix[int(img_id)] # only 1 row\n",
    "        coord_add_list = ast.literal_eval(mini_changes_df[0])\n",
    "        coord_remove_list = ast.literal_eval(mini_changes_df[1])\n",
    "        for coord_add in coord_add_list:\n",
    "            if len(coord_add) == 0:\n",
    "                continue\n",
    "            y_coord = int(coord_add[0])\n",
    "            x_coord = int(coord_add[1])\n",
    "            category = coord_add[2]\n",
    "            # changing new_coord_df to add coordinate\n",
    "            new_row = pd.Series([filename, y_coord, x_coord, category], index=[\"filename\", \"y_coord\", \"x_coord\", \"category\"])\n",
    "            new_coord_df = new_coord_df.append(new_row, ignore_index=True)\n",
    "        for coord_remove in coord_remove_list:\n",
    "            if len(coord_remove) == 0:\n",
    "                continue\n",
    "            y_coord = coord_remove[0]\n",
    "            x_coord = coord_remove[1]\n",
    "            category = coord_remove[2]\n",
    "            # changing new_coord_df to remove coordinate\n",
    "            mask = (new_coord_df['filename'] == filename) & (new_coord_df['y_coord'] == y_coord) & (new_coord_df['x_coord'] == x_coord) & (new_coord_df['category'] == category)\n",
    "            new_coord_df= new_coord_df[~mask]\n",
    "    new_coord_df.to_csv(OUT_PATH + 'correct_coordinates.csv') # save correct coordinates\n",
    "\n",
    "    # next create a new file with correct counts of sea lions\n",
    "    new_counts_df = pd.DataFrame(index = IMG_IDS, columns = [\"adult_males\", \"subadult_males\", \"adult_females\", \"juveniles\", \"pups\"]).fillna(0)\n",
    "    for row in new_coord_df.iterrows():\n",
    "        filename = row[1]['filename']\n",
    "        file_id = int(filename.partition('.')[0])\n",
    "        category = row[1]['category']\n",
    "        new_counts_df[category][file_id] +=1\n",
    "    new_counts_df.to_csv(OUT_PATH + 'correct_train.csv',index_label='train_id')\n",
    "apply_all_changes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results\n",
    "Now the final results have been generated and the correct coordinates and counts are located in **correct_coordinates.csv**, and **correct_train.csv** respectively. If you run this entire notebook up to this point, you should be able to generate the exact same coordinates file from [here](https://github.com/LivingProgram/kaggle-sea-lion-data/blob/master/correct_coordinates.csv) and counts file from [here](https://github.com/LivingProgram/kaggle-sea-lion-data/blob/master/correct_train.csv). Take note that for all the bad images (images from Mismatched Train), they will not have coordinates for their file within the **correct_coordinates.csv**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying the Results\n",
    "I have described my methodology to generate coordinates, and really the only way to check the results is to mark the images using the coordinates and verifying their authenticity. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
